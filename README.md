# âš–ï¸ JurisRAG  
### AI-Powered Legal Information Retrieval System  

---

## ğŸ“˜ Overview

**JurisRAG** is an AI-powered legal information retrieval system built using Retrieval-Augmented Generation (RAG).  
It enables users to query statutory documents and receive accurate, context-grounded responses.

Instead of relying purely on a language modelâ€™s internal knowledge, JurisRAG retrieves relevant legal sections from indexed statutory documents and generates answers grounded in that retrieved context. This significantly reduces hallucination and improves reliability in the legal domain.

---

## ğŸš€ Key Features

- ğŸ“„ PDF-based statutory corpus ingestion  
- ğŸ” Semantic search using FAISS vector indexing  
- ğŸ§  Context-aware response generation (RAG architecture)  
- âš¡ Fast nearest-neighbor retrieval  
- ğŸ’¬ Clean Streamlit-based interactive UI  
- ğŸ” Secure API key management via environment variables  

---

## ğŸ—ï¸ System Architecture

### 1ï¸âƒ£ Data Ingestion & Indexing Pipeline

```
PDF Loader  
   â†“  
Text Extraction  
   â†“  
Sliding-Window Chunking  
   â†“  
Embedding Generation (MiniLM)  
   â†“  
FAISS Vector Store  
```

### 2ï¸âƒ£ Query Processing Flow

```
User Query  
   â†“  
Query Embedding  
   â†“  
Top-K Semantic Retrieval  
   â†“  
LLM Response Generation (Groq - Llama Model)  
   â†“  
Final Context-Grounded Answer  
```

---

## ğŸ› ï¸ Technologies Used

### ğŸ”¹ Backend & RAG
- LangChain  
- FAISS (Vector Database)  
- HuggingFace Sentence Transformers  
- Groq (Llama Model API)  

### ğŸ”¹ Frontend
- Streamlit  

### ğŸ”¹ Supporting Libraries
- PyPDF  
- Python-dotenv  
- NumPy  
- Transformers  
- Torch  

---

## ğŸ“š Legal Corpus Indexed

The system indexes statutory documents including:

- Copyright Act  
- Criminal Law Amendment Act 2018  
- Indian Penal Code  
- Companies Act 2013  
- Constitution of India  
- Additional legal PDF documents  

---

## âš™ï¸ Installation Guide

### 1ï¸âƒ£ Clone the Repository

```bash
git clone <your-repository-link>
cd JurisRAG
```

### 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Configure API Key

Create a `.env` file in the root directory:

```
GROQ_API_KEY=your_api_key_here
```

### 4ï¸âƒ£ Run the Ingestion Pipeline

```bash
python ingestion.py
```

This generates the FAISS vector store from the legal corpus.

### 5ï¸âƒ£ Launch the Application

```bash
streamlit run app.py
```

---

## ğŸ“‚ Project Structure

```
JurisRAG/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ ingestion.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â”œâ”€â”€ my_vector_store/
â””â”€â”€ LEGAL-DATA/
```

---

## ğŸ¯ How It Works

1. Legal PDFs are loaded and parsed.
2. Text is split using sliding-window chunking.
3. Each chunk is converted into embeddings using MiniLM.
4. Embeddings are stored in a FAISS vector index.
5. When a user query is submitted:
   - The query is embedded
   - Top relevant chunks are retrieved
   - Retrieved context is passed to the LLM
   - A grounded answer is generated

---

## ğŸ§  Why RAG Instead of Pure LLM?

Traditional LLM-based systems:
- May hallucinate
- Lack document grounding
- Cannot verify source relevance

RAG-based systems:
- Retrieve actual legal text
- Reduce hallucination
- Improve factual accuracy
- Provide explainable, context-backed responses

---

## ğŸ“Œ Limitations

- Dependent on quality and completeness of indexed documents  
- Does not replace professional legal consultation  
- Retrieval accuracy depends on chunking and embedding strategy  

---

## ğŸ”® Future Improvements

- ğŸ“¤ User-uploaded document support  
- ğŸ’¾ Save chat history feature  
- ğŸ“Š Confidence scoring for responses  
- ğŸ” Section-wise citation highlighting  
- â˜ï¸ Cloud deployment (Docker / AWS / GCP)  

---

## ğŸ‘¨â€ğŸ’» Authors

- Harsh Balkrishna Vahal   

---

## ğŸ“œ License

This project is developed for academic and research purposes.
